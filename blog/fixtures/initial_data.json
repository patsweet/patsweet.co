[{"pk": 1, "model": "blog.post", "fields": {"body": "<p>Welcome to my new website.</p>\r\n<p>This lovely piece of internet real estate has been in the works for some time. Honestly, it should have been completed a long while ago, but I've been putting off coding everything up.</p>\r\n<p>You see, this blog is powered by Django and more-or-less homegrown. I say more-or-less because it relies, like most projects, on the kindness of strangers and takes advantage of several Django packages, including:</p>\r\n<ul>\r\n<li>grappelli - For a sexier admin interface (that you'll probably never see)</li>\r\n<li>django-filebrowser - For incorporating images and other media into posts</li>\r\n<li>django-tinymce - For styling blog post text (e.g.&nbsp;<strong>bold</strong> and&nbsp;underlined text).&nbsp;</li>\r\n</ul>\r\n<p>My goal is to update this blog more frequently than I did my Tumblr. I've migrated some content from the last blog, but you won't see the random food pictures and nonsense from the old site.</p>", "category": 1, "author": 1, "headline": "Hello world!", "created_on": "2014-02-28T05:14:20.702Z", "published": true, "pub_date": "2014-02-28T00:14:00Z", "slug": "hello-world"}}, {"pk": 3, "model": "blog.post", "fields": {"body": "<p>I&rsquo;m not quite sure I can summarize everything I learned at this year&rsquo;s NICAR conference in Baltimore. There&rsquo;s simply too much.</p>\r\n<p>Here, however, are the highlights that I know I&rsquo;ll be putting to use in The News Journal newsroom:</p>\r\n<h3>Statistics: Our new best friend</h3>\r\n<p>I attended a few panels on better using stats in the newsroom (one of which was even called &ldquo;Enhance your stories with statistics&rdquo;). We&rsquo;ve done some rudimentary statistics quite bit, finding means, medians and even modes to explore different various topics.</p>\r\n<p>Beyond that, our only real venture into more complicated number crunching was how we ranked the most Dangerous Intersections. Looking back, our ranking math wasn&rsquo;t bad, but we can now do it much more easily and with fewer Google queries.</p>\r\n<p>For posterity&rsquo;s sake, here are the tipsheets from some of the stats sessions at NICAR:</p>\r\n<ul>\r\n<li><a href=\"https://github.com/myersjustinc/nicar14-notes/blob/77418cd6692f6bc772571fb3d7c83fceec67e976/20140227_1000-enhance_your_stories_with_statistics.txt\" target=\"_blank\">Justin Myer&rsquo;s notes from &ldquo;Enhance your stories with stastics&rdquo;</a></li>\r\n<li><a href=\"http://www.ats.ucla.edu/stat/sas/whatstat/\" target=\"_blank\">What statistical analysis should I use?</a></li>\r\n<li><a href=\"http://jenster.com/stats2011.pdf\" target=\"_blank\">Stats for stories</a></li>\r\n</ul>\r\n<h3>This is the year I learn R</h3>\r\n<p>There were quite a few sessions teaching/promoting R, the stats-based programming language. I&rsquo;ve played with the language off and on for a while, but after attending a few sessions I realized I should really put more focus into the language.</p>\r\n<p>If anything, being able to open RStudio and quickly visualize data will help me work more quickly and discover stories that I might not have found.</p>\r\n<h3>I (kind of) want to kill some servers</h3>\r\n<p>Most all of the headaches I&rsquo;ve had recently involve server issues. We were hacked at the end of 2012 and I spent a good portion of 2013 rebuilding and securing one of our LAMP servers. No more.</p>\r\n<p>We won&rsquo;t be able to completely cut the chord, but I can at least put more emphasis on building flat apps. If the server should go down in the future, it&rsquo;d be nice to be able to just open up the command line and type `fab deploy` and have everything pushed and restored.</p>\r\n<p>As I continue going through notes, I might have some addenda to this post, but those three points should keep me busy for a while.</p>", "category": 2, "author": 1, "headline": "NICAR postmortem", "created_on": "2014-03-08T21:33:37.116Z", "published": true, "pub_date": "2014-03-05T00:00:00Z", "slug": "nicar-postmortem"}}, {"pk": 5, "model": "blog.post", "fields": {"body": "<p>It&rsquo;s that most wonderful time of the year, the annual NICAR conference. For the uninitiated, this is the conference where journalists from all over the country (and from many other countries) get together to talk data, open records, technology and all the other wonderful components that make up the world of computer-assisted reporting (i.e. CAR or data journalism).</p>\r\n<p>This year&rsquo;s conference is conveniently located in Baltimore and, as in previous years, is off to a strong start. My goal is to leave birdland with a better understanding of statistics and the R programming language. I spend most of my days writing PHP, Python and JavaScript to clean up and visualize data, but the more I explore R, the more I am convinced that it would be a fantastic tool for cleaning, analyzing and even visualizing data.</p>\r\n<h3>Getting a better grasp on statistics</h3>\r\n<p>One of the highlights for today was the &ldquo;Enhance your stories with statistics&rdquo; session. The speakers moved a bit quick, but they helped answer one of the questions I always have when applying statistcs: what statistical test should I use to analyze my variables? I&rsquo;ll still need a lot of googling, but I at least have a better understanding of when to use a T-test, ANOVA or Fischer&rsquo;s Exact test. All I have to do now is find a story to apply this info.</p>\r\n<h3>Using R in the newsroom</h3>\r\n<p>I love Python. PHP can certainly get the job done. JavaScript, surprisingly, makes a lot of sense to me. R, however, just seems odd. Steven Rich put it best today: &ldquo;The best thing about R is that it was written by statisticians&hellip; The worst thing about R is that it was written by statisticians.&rdquo;</p>\r\n<p>Through my own studies and a session today, I&rsquo;ve started forming a collection of code snippets that I know will work to solve common problems. Need to read a csv file into RStudio? I can write the code for that. Need to mash together a shapefile with a dataset and render it? I can google the code to do that&hellip;</p>\r\n<p>I just need practice. Part of me wants to commit to using R for every data cleaning and analysis task I undergo for the next two weeks. The other part of me, though, likes hitting deadlines and not going insane. Either way, I&rsquo;ll be finding some time to get a better grasp on R.</p>\r\n<h3>Tomorrow</h3>\r\n<p>Tomorrow should be a little more relaxed but equally rewarding. Melissa and I&rsquo;s &ldquo;Most Dangerous Intersections&rdquo; story is being featured in the &ldquo;Year in CAR&rdquo; presentation at 9 a.m., so we&rsquo;ll get 2 or 3 minutes to share how we put it together and brag about its impact. After that, it&rsquo;s a full slate of data journalism, and I&rsquo;ll hopefully be recapping the highlights here tomorrow.</p>\r\n<p>Until then&hellip;</p>", "category": 2, "author": 1, "headline": "#NICAR - Day One", "created_on": "2014-03-08T21:48:54.099Z", "published": true, "pub_date": "2014-02-28T00:00:00Z", "slug": "nicar-day-one"}}, {"pk": 6, "model": "blog.post", "fields": {"body": "<p>The past year seemed to fly by, and after looking at the server where I publish a lot of my work, I think I know why 2013 seemed so quick. It was busy.</p>\r\n<h3>What didn&rsquo;t we map?</h3>\r\n<p>Looking back, I realized that I spent a lot of time building maps. Some of them were more interesting than others, and they varied quite a bit in complexity. In no particular order, here are some of my favorites:</p>\r\n<ul>\r\n<li>In the fall, DelDOT was warning drivers about deer on the roadway. Of course, we had to find out where the most deer-related accidents occur. Solution: a heatmap that told readers to be wary while driving in the Pike Creek area.&nbsp;<a href=\"http://php.delawareonline.com/news/2013/deer/\" target=\"_blank\">Link.</a></li>\r\n<li>Transportation was a hot topic for me this year thanks to transportation reporter&nbsp;<a href=\"https://twitter.com/nannburke\" target=\"_blank\">Melissa Nann Burke</a>&nbsp;getting her hands on a database of car accidents from the state. She and I spent a ton of time trying to figure out which intersections were the most dangerous in the state. That turned into a pretty nifty map and database that I&rsquo;ll probably keep in my clips for a long while.&nbsp;<a href=\"http://php.delawareonline.com/news/2013/ecrash/\" target=\"_blank\">Link.</a></li>\r\n<li>This last map that I&rsquo;ll share is only notable because it was a challenge getting the very complex geometries of probabilistic storm surge to render without crashing a browser tab. I only have FTP access to the server (I know&hellip; ughh) so I could either publish map tiles on our severely over-worked mapping server that is destined to crash or try to fine-tune loading geojson. In the end, geojson ended up working out pretty well.&nbsp;<a href=\"http://php.delawareonline.com/news/2013/sandy/\" target=\"_blank\">Link.</a></li>\r\n</ul>\r\n<h3>d3.js is too much fun</h3>\r\n<p>This was also the year where I got to play more with&nbsp;<a href=\"http://d3js.org/\" target=\"_blank\">d3.js</a>. I&rsquo;d still love to do more with the JavaScript library in the future, but I managed to have quite a bit of fun with it. Case in point: one of the best pieces of feedback I got from a reader this year was in response to a chart I built with d3 that accompanied a story by our higher-ed reporter,&nbsp;<a href=\"https://twitter.com/nicholedobo\" target=\"_blank\">Nichole Dobo</a>.</p>\r\n<p>She was writing about a lawsuit against Widener Law School in which alumni argued that the school misrepresented its post-grad employment stats. Using figures that Nichole got from the American Bar Association, I built&nbsp;<a href=\"http://php.delawareonline.com/news/2013/widener/\" target=\"_blank\">a chart that showed the employment stats for law schools across the U.S.</a>&nbsp;I included the data in tabular form below the chart, but judging from the feedback I received, most users spent a lot of time changing the values on each axis and looking at schools state-by-state.</p>\r\n<p>Here are a few other d3 graphics that made an appearance on delawareonline.com:</p>\r\n<ul>\r\n<li>Force-directed graphs? Why not. This chart showed how developers were able to legally skirt campaign finance limits through collections of LLCs.&nbsp;<a href=\"http://php.delawareonline.com/news/2013/contributions/\" target=\"_blank\">Link</a></li>\r\n<li>A chart similar to the law schools one that shows Occupational Employment Statistics for the state. This debuted with a story examining how the shrinking number of middle-wage jobs has/will impact the state.&nbsp;<a href=\"http://php.delawareonline.com/news/2013/imagine-jobs/\" target=\"_blank\">Link</a></li>\r\n<li>This last one doesn&rsquo;t get a link because it was only visible to folks who signed up for our now-closed Keep the Beat exercise program. The dashboard (pictured at the top) where users reported minutes of physical activity, though, used d3 to keep folks up-to-date on their progress.</li>\r\n</ul>\r\n<h3>PHP and Django</h3>\r\n<p>As in my first year at The News Journal, 2013 saw a few heavy projects that required a lot of back-end scripting. One of the largest undertakings was the Keep the Beat website that I mentioned above. Unfortunately, it was a ten-week program with a limited window to register, so it&rsquo;s more-or-less dead now that it&rsquo;s over.</p>\r\n<p>For me, though, it was an excellent lesson in Object-Oriented PHP. I built the registration/login and session management stuff from scratch (something I had never done&hellip; because Django) and was super happy that a few relatively small classes could handle the bulk of the work. Someone with a lot more experience with PHP might bang their head on a desk when looking at it, but I tried my best to include decent documentation and keep things modular. In the end, the system performed quite well and I&rsquo;m looking forward to being able to reuse a lot of the code.</p>\r\n<p>One of the other big projects was pretty cool but is currently making me a bit sore. Last January, I built a Django app that allowed folks to register and submit camps for our annual summer camps guide. Why did I choose Django? User and session management was a breeze and it came together really quickly, plus we do this every year and I wanted to reuse and reuse and reuse and&hellip; you get it. The app ended up being a solid success and we had more camps submitted than in any prior year. So, why am I not happy with it? It&rsquo;s currently dead because the decision was made to overhaul most of the features, including ditching the user profile where folks could manage/edit their submissions. I ended up tossing most of the code and rewriting it in PHP on a very tight deadline before the holidays. Thanks to what I learned about object-oriented PHP from the Keep the Beat site, though, hopefully this version will be just as reusable as the Django app.</p>\r\n<p>Lastly, this post wouldn&rsquo;t be complete with a mention of the Wilmington Shootings tracker. I built it in 2012, but 2013&rsquo;s record-breaking year of violence in Wilmington saw the app getting a lot of use and it continues to be very valuable not only for readers, but reporters looking for stats too.</p>\r\n<p>Hopefully 2014 will be just as productive as 2013. I plan on finding at least one project to build with Backbone.js and migrating all of our Django apps from 1.3 to 1.6 and making some necessary/fun upgrades. And, as I say every year, ideally I&rsquo;ll be updating this blog more often.</p>", "category": 2, "author": 1, "headline": "Some 2013 work highlights", "created_on": "2014-03-08T22:10:05.435Z", "published": true, "pub_date": "2014-01-02T00:00:00Z", "slug": "some-2013-work-highlights"}}, {"pk": 7, "model": "blog.post", "fields": {"body": "<p>After months of analysis, reporting and delays, Melissa Nann Burke and I finally saw our analysis of the most dangerous intersections in Delaware grace A1&nbsp;of The News Journal.</p>\r\n<p><strong><a href=\"http://archive.delawareonline.com/article/20130714/NEWS1501/307140036/Delaware-s-dangerous-intersections\" target=\"_blank\">STORY: Delaware&rsquo;s Dangerous Intersections</a></strong></p>\r\n<p><strong><a href=\"http://archive.delawareonline.com/dangerous-intersections\" target=\"_blank\">INTERACTIVE MAP: Most Dangerous Intersections</a></strong></p>\r\n<p>Our analysis focused on the 185 intersections that averaged at least 15 crashes per year between 2010 and 2012. I&rsquo;ll defer to the story for a discussion of the findings, though. Here, I want to focus on how the analysis was done.</p>\r\n<h3>THE ANALYSIS</h3>\r\n<h4>Tools: QGIS, PostgreSQL+PostGIS</h4>\r\n<p>We obtained a geo-database of all reported crashes in the state (which might be a huge perk of covering a small state) and used it to expand an analysis by a local transportation-planning agency called WILMAPCO that does something similar for only New Castle County. To do this, we needed a database (or shapefile) of polygons for every intersection in the state. We also needed the traffic volumes so we could normalize the data and be able to compare the smaller rural intersections with the big-city and suburban ones.</p>\r\n<p>For all the intersection polygons, we started with a shapefile of intersection points we obtained from DelDOT. Instead of just creating buffers, though, we had to painstakingly go through each intersection and draw the &ldquo;sphere of influence&rdquo; - basically the area where a driver&rsquo;s decision is impacted by the intersection such as acceleration and turning lanes and the heart of the intersection itself - to keep our analysis in line with WILMAPCO&rsquo;s. Fortunately, WILMAPCO gave us their New Castle County shapefile, so Melissa and I each took a remaining county and started drawing.</p>\r\n<p>As annoying as drawing hundreds of intersections sounds, dealing with traffic volumes was even worse. While the volumes were easy for the major intersections, the the crossroads for many small and some mid-size intersections didn&rsquo;t have traffic counts and we were forced to use estimates based on a formula the state also uses that takes into account land use (Housing development A has 200 occupied homes. &nbsp;Multiply that by the average number of trips for an occupant. Etc. etc.). Those didn&rsquo;t give us absolute numbers, but they gave us a strong enough estimate that we could say there were at least X crashes per 1 million vehicles entering the intersection.</p>\r\n<p>With polygons complete and traffic numbers in hand, I threw everything into a PostGIS database and started running spacial joins and calculating a few fields. It was really nice to be able to write SQL to take care of the analysis instead of dealing with the QGIS gui. It was much faster and made it a breeze to export snapshots to excel.</p>\r\n<p>The last bit of tinkering was that we scored each of the 185 intersections based on how they compared with the others on total crash rate and injury crash rate. If the injury crash rate was high compared to other intersections, it scored higher, and the same went with the total crash rate. This meant that an intersection with an average crash rate but with a larger rate of injury accidents could score higher than an intersection with a higher crash rate but a lower injury crash rate.</p>\r\n<h3>THE INTERACTIVE:</h3>\r\n<h4>Tools:&nbsp;<a href=\"http://leafletjs.com\" target=\"_blank\">Leaflet.js</a>,&nbsp;<a href=\"http://www.datatables.net\" target=\"_blank\">DataTables.js</a>, jQuery</h4>\r\n<p>Because our analysis took place in PostGIS, it was a breeze to turn our intersections data as geojson. To make it much more accessible, though, I converted our polygons back to points by calculating each centroid. That left me with a nice, small geojson file that I could display on a leaflet map.</p>\r\n<p>For those that didn&rsquo;t want to just look at the worst intersections near them, though, I wanted to put together a datatable that folks could sort and search. That was easy with datatables.js. The fun part, was tying together the interactivity of the datatable with the leaflet map. Here&rsquo;s the code I used:</p>\r\n<script type=\"text/javascript\" src=\"https://gist.github.com/patsweet/6001283.js\"></script>", "category": 2, "author": 1, "headline": "Delaware's dangerous intersections", "created_on": "2014-03-08T22:23:14.602Z", "published": true, "pub_date": "2013-07-15T00:00:00Z", "slug": "delawares-dangerous-intersections"}}, {"pk": 8, "model": "blog.post", "fields": {"body": "<p>I&rsquo;ve been meaning to post this for a while and was reminded when I saw a post from Anthony DeBarros about using xlrd to parse an Excel document.</p>\r\n<p>A FOIA request for voting records for Delaware state legislators returned a ton of MS Word documents, each with a table of votes for a single legislator. The State House uses a Lotus Notes database and actually stores their voting records in this format. So, I had to extract all of the votes from the files and put them in a form that I could examine with excel and later put into MySQL for publication. Here&rsquo;s the script that I used:</p>\r\n<script type=\"text/javascript\" src=\"https://gist.github.com/delawaredata/4715363.js\"></script>\r\n<p class=\"gist\"><a href=\"https://gist.github.com/delawaredata/4715363\" target=\"_blank\"><span style=\"color: #666666;\">At the heart of this script is the win32com library. The client module allows you to open up Microsoft Office applications with Python and to parse whatever is in them. In this case, we are opening an instance of MS Word in the background with lines 12-13. From there, we open each document inside the writeVotes function with lines 22-23 and select the table with line 24, &ldquo;table = doc.Tables(1)&rdquo;. Luckily, each document only had one table that we cared about, though we could have easily iterated through each table in each document.</span></a></p>\r\n<p>The rest of the script is pretty straightforward. For each row in the table, we grab the relevant information with &ldquo;.Range.text&rdquo; and join it all together.</p>\r\n<p>I hope others find this helpful. If the data didn&rsquo;t come in several dozen word files, it probably would have been easier to do a copy/paste job, but this script sped things up tremendously and made my life easier.</p>", "category": 3, "author": 1, "headline": "Parsing tables in MS Word with Python", "created_on": "2014-03-08T22:33:15.625Z", "published": true, "pub_date": "2013-01-05T00:00:00Z", "slug": "parsing-tables-ms-word-python"}}, {"pk": 9, "model": "blog.post", "fields": {"body": "<p>Election Day at The News Journal was a pretty solid success.</p>\r\n<p>We used PHP and internet duct tape (iframes) to scrape and display results for big races live on our homepage and results for all races on another landing page.</p>\r\n<p>Unlike the Primary Election, our cron job ran smooth all night and my stress level wasn't through the roof.</p>\r\n<p>The day before, though, was a little more difficult.</p>\r\n<p>We've been having issues with the main LAMP server that we use for interactive content. It's also the server that typically hosts all of our site scrapers and I, being someone who is much more comfortable with Python than PHP, was planning on re-purposing an old election results scraper.</p>\r\n<p>Instead, I had to build from scratch on another server that is dedicated to our Django projects and become a whiz with regular expressions in PHP pretty quickly. If you couldn't guess, it was quite the learning experience.</p>\r\n<p>With Python, regular expressions seemed to come easy to me, but I still probably would have used the DOM parsing library BeautifulSoup to scrape results. With PHP, though, most instructions I found said to stick with regex and it seemed easier than figuring out how to parse html. Here's an example:</p>\r\n<p>If we are looking for percent of districts reporting and the html looks like, \"GOVERNOR&lt;/td&gt;&lt;td&gt;25 of 90 districts reporting&lt;/td&gt;\", grabbing the numbers goes like this:</p>\r\n<pre class=\"prettyprint\">my_pattern = \"GOVERNOR\\D+(\\d{2})\\D+(\\d{2})\"<br />matches = re.search(my_pattern, data)<br />percent_reporting = 100 * int(matches.group(1)) / int(matches.group(2))<br />print percent_reporting<br /><br /></pre>\r\n<p>What threw me off first with PHP - other than adjusting to the syntax - was the required delimiters. The Python code above looks like this in PHP:</p>\r\n<pre class=\"prettyprint\">$my_pattern = \"~GOVERNOR\\D+(\\d{2})\\D+(\\d{2})~\";<br />preg_match($my_pattern, $data, $matches);<br />$percent_reporting = 100 * (int)$matches[1] / (int)$matches[2];<br />echo $percent_reporting;<br /><br /></pre>\r\n<p>As you can see, the actual expression was pretty much the same. I just had to wrap it in tildes. \"\\D+\" and \"\\d+\" still grab non-decimal and decimal characters respectively, and you can still pull out groups with parentheses. Not too bad, just a little different.</p>\r\n<p>Other than dealing with regular expressions, the rest of the script was pretty straightforward. I grabbed the results with CURL (instead of urllib in Python) and wrote everything to a separate file with fwrite(). Even though I felt like a stranger in a strange land at times, I found a few things extremely handy with PHP, such as using a heredoc with embedded variables to output the whole thing instead of gluing all the text together. I'm still more of a PHP&nbsp;<em>editor</em>&nbsp;than a PHP&nbsp;<em>writer</em>, but it's getting easier and easier every time.</p>", "category": 2, "author": 1, "headline": "Locked out of the server on Election Day", "created_on": "2014-03-08T22:38:36.664Z", "published": true, "pub_date": "2012-11-08T00:00:00Z", "slug": "locked-out-server-election-day"}}, {"pk": 1, "model": "blog.category", "fields": {"slug": "other", "title": "Other"}}, {"pk": 2, "model": "blog.category", "fields": {"slug": "journalism", "title": "Journalism"}}, {"pk": 3, "model": "blog.category", "fields": {"slug": "python", "title": "Python"}}]